{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bdefb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install praw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace7c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import praw\n",
    "\n",
    "reddit_read_only = praw.Reddit(client_id=\"DlcjXhOBwypg_mZEm6xlwA\",         # your client id\n",
    "                               client_secret=\"kLA5U-4G-eKi47VoCgunW1bnd2lf9Q\",      # your client secret\n",
    "                               user_agent=\"Project\")        # your user agent\n",
    "\n",
    "subreddit = reddit_read_only.subreddit(\"wallstreetbets\")\n",
    " \n",
    "# Display the name of the Subreddit\n",
    "print(\"Display Name:\", subreddit.display_name)\n",
    " \n",
    "# Display the title of the Subreddit\n",
    "print(\"Title:\", subreddit.title)\n",
    " \n",
    "# Display the description of the Subreddit\n",
    "print(\"Description:\", subreddit.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d747a6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posts_collection(stock, sort, time):\n",
    "    \n",
    "    posts_dict = {\"Title\": [], \"Post Text\": [],\n",
    "              \"ID\": [], \"Score\": [],\n",
    "              \"Total Comments\": [], \"Post URL\": [],\n",
    "              \"Date\": []\n",
    "              }\n",
    "    for name in stock:\n",
    "        for post in reddit_read_only.subreddit(\"wallstreetbets\").search(name,sort=sort,time_filter=time):\n",
    "    # Title of each post\n",
    "            posts_dict[\"Title\"].append(post.title)\n",
    "     \n",
    "    # Text inside a post\n",
    "            posts_dict[\"Post Text\"].append(post.selftext)\n",
    "     \n",
    "    # Unique ID of each post\n",
    "            posts_dict[\"ID\"].append(post.id)\n",
    "     \n",
    "    # The score of a post\n",
    "            posts_dict[\"Score\"].append(post.score)\n",
    "     \n",
    "    # Total number of comments inside the post\n",
    "            posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "     \n",
    "    # URL of each post\n",
    "            posts_dict[\"Post URL\"].append(post.url)\n",
    "\n",
    "    # Crated time of each post\n",
    "            posts_dict[\"Date\"].append(post.created_utc)\n",
    "\n",
    "    # Save posts as dataframe \n",
    "    stock_posts = pd.DataFrame(posts_dict)\n",
    "    return stock_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ff83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesla = ['tesla','TSLA']\n",
    "apple = ['apple','AAPL']\n",
    "amazon = ['amazon','AMZN']\n",
    "google = ['google','GOOG']\n",
    "meta = ['facebook','META']\n",
    "netfilx = ['netfilx','NFLX']\n",
    "time = 'year'\n",
    "\n",
    "# Collect posts for all six companies\n",
    "\n",
    "Tesla_posts = posts_collection(tesla,\"relevance\", time)\n",
    "Apple_posts = posts_collection(apple,\"relevance\", time)\n",
    "Amazon_posts = posts_collection(amazon,\"relevance\", time)\n",
    "Google_posts = posts_collection(google,\"relevance\", time)\n",
    "Meta_posts = posts_collection(meta,\"relevance\", time)\n",
    "Netfilx_posts = posts_collection(netfilx,\"top\", time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2b9964",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = Apple_posts[\"ID\"]\n",
    "a = Apple_posts[ids.isin(ids[ids.duplicated()])].sort_values(\"ID\")\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acda6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of data point in the Apple_posts is',len(Apple_posts))\n",
    "Apple_posts_clean = Apple_posts.drop_duplicates(subset=['Title'])\n",
    "print('The number of data point after removing duplicates is',len(Apple_posts_clean))\n",
    "ids = Apple_posts_clean[\"ID\"]\n",
    "a = Apple_posts_clean[ids.isin(ids[ids.duplicated()])].sort_values(\"ID\")\n",
    "print('The number of duplicates after cleaning up',len(a))\n",
    "Apple_posts_clean.to_csv(\"Apple_posts_clean.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9ef72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of data point in the Tesla_posts is',len(Tesla_posts))\n",
    "Tesla_posts_clean = Tesla_posts.drop_duplicates(subset=['Title'])\n",
    "print('The number of data point after removing duplicates is',len(Tesla_posts_clean))\n",
    "ids = Tesla_posts_clean[\"ID\"]\n",
    "a = Tesla_posts_clean[ids.isin(ids[ids.duplicated()])].sort_values(\"ID\")\n",
    "print('The number of duplicates after cleaning up',len(a))\n",
    "Tesla_posts_clean.to_csv(\"Tesla_posts_clean.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3782259f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of data point in the Meta_posts is',len(Meta_posts))\n",
    "Meta_posts_clean = Meta_posts.drop_duplicates(subset=['Title'])\n",
    "print('The number of data point after removing duplicates is',len(Meta_posts_clean))\n",
    "ids = Meta_posts_clean[\"ID\"]\n",
    "a = Meta_posts_clean[ids.isin(ids[ids.duplicated()])].sort_values(\"ID\")\n",
    "print('The number of duplicates after cleaning up',len(a))\n",
    "Meta_posts_clean.to_csv(\"Meta_posts_clean.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15732355",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of data point in the Amazon_posts is',len(Amazon_posts))\n",
    "Amazon_posts_clean = Amazon_posts.drop_duplicates(subset=['Title'])\n",
    "print('The number of data point after removing duplicates is',len(Amazon_posts_clean))\n",
    "ids = Amazon_posts_clean[\"ID\"]\n",
    "a = Amazon_posts_clean[ids.isin(ids[ids.duplicated()])].sort_values(\"ID\")\n",
    "print('The number of duplicates after cleaning up',len(a))\n",
    "Amazon_posts_clean.to_csv(\"Amazon_posts_clean.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc35fbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of data point in the Google_posts is',len(Google_posts))\n",
    "Google_posts_clean = Google_posts.drop_duplicates(subset=['Title'])\n",
    "print('The number of data point after removing duplicates is',len(Google_posts_clean))\n",
    "ids = Google_posts_clean[\"ID\"]\n",
    "a = Google_posts_clean[ids.isin(ids[ids.duplicated()])].sort_values(\"ID\")\n",
    "print('The number of duplicates after cleaning up',len(a))\n",
    "Google_posts_clean.to_csv(\"Google_posts_clean.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8276d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The number of data point in the Google_posts is',len(Netfilx_posts))\n",
    "Netfilx_posts_clean = Netfilx_posts.drop_duplicates(subset=['Title'])\n",
    "print('The number of data point after removing duplicates is',len(Netfilx_posts_clean))\n",
    "ids = Netfilx_posts_clean[\"ID\"]\n",
    "a = Netfilx_posts_clean[ids.isin(ids[ids.duplicated()])].sort_values(\"ID\")\n",
    "print('The number of duplicates after cleaning up',len(a))\n",
    "Netfilx_posts_clean.to_csv(\"Netfilx_posts_clean.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ea4cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ece1786')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "ded25959cf7d53f44c4b3badf7f90bfd886fd262d3c37a2ffcfc59b0bd91a157"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
