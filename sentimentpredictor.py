# -*- coding: utf-8 -*-
"""sentimentpredictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tPphoepyXnumAwnCzDUga2f8iUwC4e5P
"""

! pip install transformers datasets

!pip install evaluate

import numpy as np
import pandas as pd
import torch
import re
import string
import nltk
import matplotlib.pyplot as plt
from transformers import AutoTokenizer, AutoModelForSequenceClassification
nltk.download('vader_lexicon')
import random
import datasets
from torch.utils.data import DataLoader

class SentimentPredictor():
  def __init__(self, input_data, model, tokenizer, start_date, end_date):
      if isinstance(input_data, pd.DataFrame):
            self.raw = input_data
      elif isinstance(input_data, str):
            self.raw = pd.read_csv(input_data)
      self.model_name = model
      self.start_date = start_date
      self.end_date = end_date
      self.tokenizer = tokenizer

  def data_process(self):
    test_r_data = self.raw.copy()
    # print(test_r_data)
    test_r_data['Post_Concat'] = self.raw['Title'] + self.raw['Post Text'].fillna('')
    X_list = test_r_data.loc[test_r_data['Label'] == -1].index.tolist()
    # print(X_list)
    test_r_data = test_r_data.drop(X_list)
    # print(test_r_data)
    df = test_r_data[['Post_Concat', 'Time', 'Score','Label']].copy()
    # df = df.sort_values(by='Time',ascending=False)

    mask = (df['Time'] > self.start_date) & (df['Time'] <= self.end_date)
    
    df_date = df.loc[mask]
    # print(df_date)
    test_data = df_date[['Post_Concat']].copy()
    test_data = test_data.dropna()
    # Convert categorical labels to numerical
    # print(test_data)
    test_data.Post_Concat = test_data.Post_Concat.str.lower()

    #Remove handlers
    test_data.Post_Concat = test_data.Post_Concat.apply(lambda x:re.sub('@[^\s]+','',x))

    # Remove URLS
    test_data.Post_Concat = test_data.Post_Concat.apply(lambda x:re.sub(r"http\S+", "", x))

    # Remove all the special characters
    test_data.Post_Concat = test_data.Post_Concat.apply(lambda x:' '.join(re.findall(r'\w+', x)))

    #remove all single characters
    test_data.Post_Concat = test_data.Post_Concat.apply(lambda x:re.sub(r'\s+[a-zA-Z]\s+', '', x))

    # Substituting multiple spaces with single space
    test_data.Post_Concat = test_data.Post_Concat.apply(lambda x:re.sub(r'\s+', ' ', x, flags=re.I))

    test_dataset = datasets.Dataset.from_dict(test_data)
    test_dataset_dict = datasets.DatasetDict({"test":test_dataset})
    # print(test_dataset_dict)
    return test_dataset_dict

  def predict(self):
    # Load pretrained model
    tokenizer = AutoTokenizer.from_pretrained(self.tokenizer)
    model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
    # print(model)

    # Tokenize function
    def tokenize_function_test(examples):
      return tokenizer(examples["Post_Concat"], padding=True,truncation=True)
    test_dataset_dict = self.data_process()
    # print(test_dataset_dict)
    # Apply Tokenize function on test set
    tokenized_datasets_test = test_dataset_dict.map(tokenize_function_test,batched=True)
    tokenized_datasets_test = tokenized_datasets_test.remove_columns(["Post_Concat"])
    # tokenized_datasets_test = tokenized_datasets_test.rename_column("Label", "labels")
    tokenized_datasets_test.set_format("torch")
    # print(tokenized_datasets_test)
    # Dataloader
    test_dataloader = DataLoader(tokenized_datasets_test['test'], batch_size=8)
    predictions_list = []
    softmax = torch.nn.Softmax(dim=1)
    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    model.to(device)  
    for batch in test_dataloader:
      batch = {k: v.to(device) for k, v in batch.items()}
      with torch.no_grad():
        outputs = model(**batch)
      logits = outputs.logits
      # print(logits)
      predictions = torch.argmax(logits, dim=-1)
      prediction_prob = softmax(logits)
      predict = predictions.cpu().detach().tolist()
      predictions_list.append(predict)
    result = []
    for i in  predictions_list:
      for j in i:
        result.append(j)
    
    return result

model_name = '/content/drive/MyDrive/ECE1786Project/model_juliensimon'
input_data = '/content/drive/MyDrive/ECE1786Project/data_labeled/Amazon_posts_labeled.csv'
tokenizer = "juliensimon/reviews-sentiment-analysis"
start_date = '11/18/2022 00:00'
end_date = '11/24/2022 23:59'
sp = SentimentPredictor(input_data, model_name, tokenizer, start_date, end_date)
sp.predict()